{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.02 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from natasha import NamesExtractor\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Аалтонен</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Аар</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аарон</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ААРОН</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аарона</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Label\n",
       "0  Аалтонен      1\n",
       "1       Аар      0\n",
       "2     Аарон      0\n",
       "3     ААРОН      0\n",
       "4    Аарона      0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "vowels = ['а',  'я', 'ё', 'у','е', 'о', 'э', 'ю', 'и', 'ы', 'Ё', 'У', 'Е', 'Ы','А', 'О', 'Э', 'Ю', 'И', 'Я']\n",
    "alphabet = ['а','б','в','г','д','е','ё','ж','з','и','й','к','л','м','н','о','п','р','с','т','у','ф','х','ц','ч','ш','щ','ы','ь','ъ','э','ю','я']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.01 ms\n"
     ]
    }
   ],
   "source": [
    "two_let_map = {}\n",
    "k = 0\n",
    "for i in alphabet:\n",
    "    for j in alphabet:\n",
    "        two_let_map['{}{}'.format(i,j)] = k\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.01 ms\n"
     ]
    }
   ],
   "source": [
    "def map_two_last_letters(word):\n",
    "    if len(word) < 2:\n",
    "        return -2\n",
    "    last_two = word.lower()[-2:]\n",
    "    if last_two[0] not in alphabet or last_two[1] not in alphabet:\n",
    "        return -1\n",
    "    return two_let_map[last_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "def countDoubles(word):\n",
    "    l = [let for let in word.lower()]\n",
    "    return len([(x,y) for x,y in zip(l, l[1:]) if x == y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "def is_contain_symb(word):\n",
    "    word_chars = re.sub(\"[^а-яА-Я]+\", \"\", word)\n",
    "    return 0 if word_chars==word else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.01 ms\n"
     ]
    }
   ],
   "source": [
    "def is_caps(word):\n",
    "    for c in word:\n",
    "        if c.islower():\n",
    "            return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.02 ms\n"
     ]
    }
   ],
   "source": [
    "extractor = NamesExtractor()\n",
    "\n",
    "def has_name(text):\n",
    "    matches = extractor(text).as_json\n",
    "    if matches !=[]:\n",
    "        for match in matches:\n",
    "            if match['fact']:\n",
    "                if match['fact']['last']:\n",
    "                    return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.1 ms\n"
     ]
    }
   ],
   "source": [
    "words_all = pd.concat([train['Word'],test['Word']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "endings_3 = []\n",
    "for w in words_all:\n",
    "    if len(w)>3:\n",
    "        endings_3.append(w[-3:])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "cnt = Counter(endings_3)\n",
    "freq_endings_3 = dict(cnt.most_common(1000))\n",
    "\n",
    "def get_freq_endings_3(word):\n",
    "    if len(word) >= 3:\n",
    "        try:\n",
    "            return freq_endings_3[word[-3:]]\n",
    "        except:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 176 ms\n"
     ]
    }
   ],
   "source": [
    "start_2_end_2 = []\n",
    "for w in words_all:\n",
    "    if len(w)>4:\n",
    "        start_2_end_2.append(w[:2]+w[-2:])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "cnt = Counter(start_2_end_2)\n",
    "freq_start_2_end_2 = dict(cnt.most_common(5000))\n",
    "\n",
    "def get_freq_start_2_end_2(word):\n",
    "    if len(word) >= 4:\n",
    "        try:\n",
    "            return freq_start_2_end_2[word[:2]+word[-2:]]\n",
    "        except:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.1 ms\n"
     ]
    }
   ],
   "source": [
    "def prepare_features(df):\n",
    "    df['Lenght'] = df['Word'].apply(lambda x: len(x))\n",
    "    df['Vowels'] = df['Word'].apply(lambda x: sum(1 if l in vowels else 0 for l in x))\n",
    "    df['Consonants'] = df['Lenght'] - df['Vowels']\n",
    "    df['Not_null_Consonants'] = df['Consonants'].apply(lambda x: 0.001 if x==0 else x)\n",
    "    df['Vow/Conson'] = (df['Vowels'] / df['Not_null_Consonants']).astype(int)\n",
    "    df = df.drop(columns=['Not_null_Consonants'])\n",
    "    df['is_lower'] = df['Word'].apply(lambda x: 1 if x[0] == x[0].lower() else 0)\n",
    "    df['Double'] = df['Word'].apply(lambda x: countDoubles(x))\n",
    "    df['last_two_let'] = df['Word'].apply(lambda word : map_two_last_letters(word))\n",
    "    df['contain_symb'] = df['Word'].apply(lambda word: is_contain_symb(word))\n",
    "    df['is_caps'] = df['Word'].apply(lambda word: is_caps(word))\n",
    "    df['freq_endings_3'] = df['Word'].apply(lambda word: get_freq_endings_3(word))\n",
    "    df['freq_start_2_end_2'] = df['Word'].apply(lambda word: get_freq_start_2_end_2(word))\n",
    "    df['is_name_by_nata'] = df['Word'].apply(lambda word: has_name(word))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.84 s\n"
     ]
    }
   ],
   "source": [
    "train_all = prepare_features(train)\n",
    "train_all.head()\n",
    "test_all = prepare_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "      <th>Lenght</th>\n",
       "      <th>Vowels</th>\n",
       "      <th>Consonants</th>\n",
       "      <th>Vow/Conson</th>\n",
       "      <th>is_lower</th>\n",
       "      <th>Double</th>\n",
       "      <th>last_two_let</th>\n",
       "      <th>contain_symb</th>\n",
       "      <th>is_caps</th>\n",
       "      <th>freq_endings_3</th>\n",
       "      <th>freq_start_2_end_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Аалтонен</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Аар</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Аарон</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ААРОН</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Аарона</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  Label  Lenght  Vowels  Consonants  Vow/Conson  is_lower  Double  \\\n",
       "0  Аалтонен      1       8       4           4           1         0       1   \n",
       "1       Аар      0       3       2           1           2         0       1   \n",
       "2     Аарон      0       5       3           2           1         0       1   \n",
       "3     ААРОН      0       5       3           2           1         0       1   \n",
       "4    Аарона      0       6       4           2           2         0       1   \n",
       "\n",
       "   last_two_let  contain_symb  is_caps  freq_endings_3  freq_start_2_end_2  \n",
       "0           179             0        0               0                   0  \n",
       "1            17             0        0               0                   0  \n",
       "2           509             0        0             100                   0  \n",
       "3           509             0        1               0                   0  \n",
       "4           462             0        0            1052                   0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "train_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "class proba_logreg(LogisticRegression):\n",
    "    def predict(self, X):\n",
    "        return LogisticRegression.predict_proba(self, X)\n",
    "    \n",
    "class proba_lgbm(LGBMClassifier):\n",
    "    def predict(self, X):\n",
    "        return LGBMClassifier.predict_proba(self, X)\n",
    "    \n",
    "class proba_mnb(MultinomialNB):\n",
    "    def predict(self, X):\n",
    "        return MultinomialNB.predict_proba(self, X)\n",
    "    \n",
    "class proba_knn(KNeighborsClassifier):\n",
    "    def predict(self, X):\n",
    "        return KNeighborsClassifier.predict_proba(self, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 133 ms\n"
     ]
    }
   ],
   "source": [
    "def stack(x_train_cur,y_train,x_test,y_test):\n",
    "    \n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    ngram_range=(2, 3),\n",
    "    max_features=50000)\n",
    "        \n",
    "    x_train_char = x_train_cur['Word']#.apply(lambda x: x.lower())\n",
    "    x_test_char = x_test['Word']#.apply(lambda x: x.lower())\n",
    "    char_vectorizer.fit(x_train_char)\n",
    "    train_char_features = char_vectorizer.transform(x_train_char)\n",
    "    test_char_features = char_vectorizer.transform(x_test_char)\n",
    "    scaler = StandardScaler()\n",
    "    x_train_std = scaler.fit_transform(x_train_cur.drop(columns=['last_two_let','Word']))\n",
    "    x_test_std = scaler.transform(x_test.drop(columns=['last_two_let','Word']))\n",
    "    \n",
    "    \n",
    "    x_train_cur = x_train_cur.drop(columns=['Word'])\n",
    "    x_test = x_test.drop(columns=['Word'])\n",
    "    \n",
    "    gbayes = proba_mnb(alpha=100)\n",
    "    y_pred_gbayes = cross_val_predict(gbayes, x_train_cur.drop(columns=['last_two_let']), y_train, cv=3)\n",
    "    gbayes.fit(x_train_cur.drop(columns=['last_two_let']), y_train)\n",
    "    gbayes2 = proba_mnb(alpha=1)\n",
    "    y_pred_gbayes2 = cross_val_predict(gbayes2, train_char_features, y_train, cv=3)\n",
    "    gbayes2.fit(train_char_features, y_train)\n",
    "    lgbm = proba_lgbm(n_estimators=300)\n",
    "    y_pred_lgbm = cross_val_predict(lgbm, x_train_cur, y_train, cv=3)\n",
    "    lgbm.fit(x_train_cur,y_train)\n",
    "    logreg_char = proba_logreg(C=0.15)\n",
    "    y_pred_logreg = cross_val_predict(logreg_char, train_char_features, y_train, cv=3)\n",
    "    logreg_char.fit(train_char_features,y_train)\n",
    "    kn = proba_knn(40)\n",
    "    y_pred_kn = cross_val_predict(kn, x_train_std, y_train, cv=3)\n",
    "    kn.fit(x_train_std,y_train)\n",
    "\n",
    "    new_x_train = pd.DataFrame()\n",
    "    new_x_train['lgbm'] = y_pred_lgbm[:,1]\n",
    "    new_x_train['bayes'] = y_pred_gbayes[:,1]\n",
    "    new_x_train['bayes2'] = y_pred_gbayes2[:,1]\n",
    "    new_x_train['logreg'] = y_pred_logreg[:,1]\n",
    "    new_x_train['kn'] = y_pred_kn[:,1]\n",
    "    new_x_train = pd.concat([new_x_train.reset_index(drop=True),x_train_cur.reset_index(drop=True)], axis=1, ignore_index=True)\n",
    "\n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(new_x_train, y_train)\n",
    "\n",
    "    y_pred_gbayes = gbayes.predict_proba(x_test.drop(columns=['last_two_let']))\n",
    "    y_pred_gbayes2 = gbayes2.predict_proba(test_char_features)\n",
    "    y_pred_lgbm = lgbm.predict_proba(x_test)\n",
    "    y_pred_logreg = logreg_char.predict_proba(test_char_features)\n",
    "    y_pred_kn = kn.predict_proba(x_test_std)\n",
    "    \n",
    "    new_x_test = pd.DataFrame()\n",
    "    new_x_test['lgbm'] = y_pred_lgbm[:,1]\n",
    "    new_x_test['bayes'] = y_pred_gbayes[:,1]\n",
    "    new_x_test['bayes2'] = y_pred_gbayes2[:,1]\n",
    "    new_x_test['logreg'] = y_pred_logreg[:,1]\n",
    "    new_x_test['kn'] = y_pred_kn[:,1]\n",
    "    new_x_test = pd.concat([new_x_test.reset_index(drop=True),x_test.reset_index(drop=True)], axis=1, ignore_index=True)\n",
    "    \n",
    "    y_pred = xgb.predict_proba(new_x_test)\n",
    "    \n",
    "    score = 0\n",
    "    if y_test is not None:\n",
    "        score = roc_auc_score(y_test, y_pred[:,1])\n",
    "    \n",
    "    return score, y_pred[:,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9064230573058735, 0.8978151809580688, 0.8973256220174763, 0.868256740287958, 0.9056078049062455]\n",
      "Mean: 0.8950856810951244\n",
      "time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "roc_auc_all = []\n",
    "x_train = train_all.drop(columns=['Label'])\n",
    "y_train = train_all[['Label']]\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "for train_idx, test_idx in kf.split(x_train, y_train):\n",
    "    x_train_cur = x_train.loc[train_idx]\n",
    "    y_train_cur = y_train.loc[train_idx].values.ravel()\n",
    "    x_test_cur = x_train.loc[test_idx]\n",
    "    y_test_cur = y_train.loc[test_idx].values.ravel()\n",
    "    \n",
    "    stacked = stack(x_train_cur, y_train_cur, x_test_cur, y_test_cur)\n",
    "    roc_auc_all.append(stacked[0])\n",
    "print(roc_auc_all)\n",
    "print('Mean: {}'.format(np.mean(roc_auc_all)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "x_train_cur = train_all.drop(columns=['Label'])\n",
    "y_train = train_all[['Label']]\n",
    "x_test = test_all\n",
    "\n",
    "_, predict = stack(x_train, y_train.values.ravel(), x_test, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.288484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.297076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.221595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.124030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.174292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Prediction\n",
       "0   0    0.288484\n",
       "1   1    0.297076\n",
       "2   2    0.221595\n",
       "3   3    0.124030\n",
       "4   4    0.174292"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.6 ms\n"
     ]
    }
   ],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['Id'] = test.index\n",
    "submit['Prediction'] = predict\n",
    "submit[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 492 ms\n"
     ]
    }
   ],
   "source": [
    "submit.to_csv('benchmark.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
